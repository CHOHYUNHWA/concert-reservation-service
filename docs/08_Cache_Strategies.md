# 캐싱을 이용한 서비스 개선

## Cache

### About Cache

#### 캐시란, 자주 사용되거나 반복적으로 조회되는 데이터를, 일반 저장소(예: 하드디스크, 네트워크 스토리지)보다 훨씬 빠른 접근 속도를 가진 저장소(예: 메모리, SSD 등)에 임시로 저장하여 응답 속도와 처리 성능을 향상시키는 기법



- **캐시의 특징**
  - 빠른 I/O 속도: 캐시는 메모리와 같이 입출력이 빠른 저장소를 활용
  - 데이터 접근 최적화: 빈번하게 요청되는 데이터를 미리 보관함으로써 데이터 조회 시간을 단축


- **참고사항**
  - 레디스는 캐시가 아니다.(**Redis != Cache**) 
    - 레디스는 NoSql기반의 In-memory DB로써 HDD 나 SDD보다 조회가 빠른 Storage이지 캐시가 아니다.
    - 쉽게 말해서, Redis는 캐시기법을 사용하기 위한 Data 저장소이지 Cache 자체가 아님
  - **캐시는 반드시 RAM을 사용하는 것은 아니다.**
    - 캐시는 데이터를 빠르게 접근하기 위한 기술로 일반적으로 RAM을 많이 이용하지만, 반드시 휘발성 메모리(RAM)만을 사용하지는 않는다.
    - 예를 들어, 웹 브라우저에서 웹 페이지에 접근할 때, CSS나 JS와 같은 정적 리소스는 브라우저 캐시 또는 Local Storage에 저장된다. 이 경우, 해당 데이터는 디스크에 저장되지만, 네트워크를 통해 매번 다운로드 받지 않고 로컬에서 빠르게 읽어올 수 있으므로 캐싱의 효과를 누릴 수 있다. 
    - 따라서, 캐시는 메모리뿐만 아니라 디스크 등 다양한 저장 매체를 활용할 수 있으며, 중요한 것은 데이터에 빠르게 접근할 수 있도록 하는 점이다.
---

## Local Cache 와 Global Cache

### 1. Local Cache

- **특징**
  - Application Layer Cache는 어플리케이션 서버 내부에서 동작하는 캐시로, 주로 메모리 기반 캐시(Java/Spring 기준 예: Ehcache, Caffeine, Guava Cache 등)를 사용
  - 어플리케이션 프로세스 내부에서 직접 데이터를 캐싱하므로, 접근 속도가 매우 빠름
  - 로컬 서버의 자원(메모리, 경우에 따라 디스크)을 활용하여 데이터를 저장
- **장점**
  - 빠른 I/O 성능: 캐시 데이터가 애플리케이션 내부에 존재하므로, 네트워크 지연 없이 매우 빠르게 읽고 쓰기 가능
  - 네트워크 비용 없음: 별도의 외부 네트워크 호출 없이 로컬 자원으로 캐싱 처리가 가능하여, 네트워크 오버헤드가 발생하지 않음
  - 비교적 간단한 구현 및 관리: 복잡한 분산 시스템 구성 없이 애플리케이션 내부에서 바로 사용 가능
- **단점**
  - 데이터 일관성 문제: 분산환경에서 각 서버마다 로컬 캐시가 존재하는 경우, 서버 간 캐시의 갱신 주기나 업데이트 타이밍이 달라 데이터의 일관성이 깨질 수 있음
  - 서버 장애 시 데이터 손실: 로컬 캐시는 애플리케이션 프로세스의 메모리를 사용하므로, 서버가 재시작되거나 장애가 발생하면 캐시 데이터가 소실될 수 있음
  - 메모리 제한: 서버에 할당된 메모리 용량이 낮은 경우, 캐시할 수 있는 데이터의 양이 제한될 수 있음

### 2. Global Cache
- **특징**
  - 중앙 집중형 캐시: 여러 애플리케이션 서버나 서비스(분산환경)에서 하나의 공유 캐시 서버를 통해 데이터를 캐싱하는 시스템
  - 대표적인 솔루션: Redis, Memcached등이 있으며, In-memory 데이터 저장소를 사용
  - 애플리케이션 서버 간에 캐시를 공유하여 데이터의 일관성을 보자 쉽게 유지 가능
- **장점**
  - 데이터 일관성 유지 용이: 모든 어플리케이션 서버가 동일한 캐시 서버를 사용하므로, 데이터 변경 시 일관된 결과를 제공 가능
  - 확장성: 글로벌 캐시 시스템은 클러스터링이나 복제 구성(Replication)을 통해 확장이 가능
  - 중앙 관리 용이: 캐시 정책, 만료 시간, 갱신 전략등을 중앙에서 통일하여 관리 가능
- **단점**
  - 추가 인프라 비용 발생: 별도의 캐시 서버를 구축하고 운영해야 하므로, 관리 포인트가 늘어나고 비용 증가
  - 네트워크 지연: 애플리케이션 서버와 캐시 서버 간의 네트워크 통신이 필요하므로, 로컬 캐시에 비해 지연(latency)가 발생
  - 단일 장애점(SPOF) 가능성: 캐시 서버가 단일 장애점이 될 수 있으므로, 고가용성(HA) 구성이나 복제, 페일오버(failover) 전략을 마련해야함


## 캐싱 전략과 주의사항

#### 캐싱 전략은 크게 읽기전략과 쓰기전략으로 나뉘고 읽/쓰기 전략을 적절히 조합하여 사용한다.

### 1. 읽기 전략

<img src="/docs/img/cache/LookAside.png"  style="background: white" alt="Look Aside Cache Strategy" width="670">

- **Look Aside(Cache Aside) 전략 특징**
  - 애플리케이션이 캐시를 먼저 조회
  - Cache Miss 발생 시 애플리케이션이 DB에서 데이터를 조회 후 캐시에 저장
  - 캐시 갱신 시, 애플리케이션이 명시적으로 캐시를 업데이트해야 함
- **장점**
  - 캐시 메모리 효율적 사용: 자주 사용되는 데이터만 캐시에 저장
  - DB 트래픽 감소: 한 번 캐시에 저장되면 이후에 DB 조회 없이 빠르게 응답
  - 단순한 구현: 캐시 정책을 애플리케이션 레벨에서 관리 가능
- **단점**
  - Cache Miss 발생 시 초기 성능 저하: 첫 번째 요청은 무조건 DB에서 가져와야 함으로 지연 발생
  - 캐시 일관성 문제: 데이터 변경 시 캐시를 업데이트하거나 기존 캐시를 삭제해야 함

<br/>

<img src="/docs/img/cache/ReadThrough.png" style="background: white" alt="Look Aside Cache Strategy" width="670">

- **Read Through 전략 특징**
  - 애플리케이션은 항상 캐시 서버를 조회
  - Cache Miss 발생 시, 캐시 서버가 직접 DB에서 데이터를 가져와 캐시에 저장
  - 애플리케이션은 캐시에 있는 데이터만 사용하고, DB에는 접근하지 않음
- **장점**
  - 캐시 관리 자동화: 애플리케이션 레벨에서 캐시를 관리할 필요 없음
  - 데이터 일관성 향상: 캐시가 자동으로 최신 데이터를 유지
  - DB 부하 감소: 캐시 서버가 DB에서 데이터를 가져오기 때문에 DB 트래픽 감소
- **단점**
  - 캐시 서버 장애 시 데이터 조회 불가: 캐시 서버가 다운되면 데이터 조회에 문제가 발생할 수 있어 적절한 FailOver 설정이 필요
  - 복잡한 설정 필요: 캐시 서버가 DB와 동기화 되도록 하기 위해 추가적인 설정이 필요(RedisGear, 별도의 Worker 서버 셋팅)

<br/>

### 2. 쓰기 전략

<img src="/docs/img/cache/WriteBack.png" style="background: white" alt="Look Aside Cache Strategy" width="670">

- **Write Back 전략 특징**
  - 애플리케이션이 먼저 캐시에 데이터를 저장하고 즉시 쓰기 완료 응답
  - 캐시 서버는 저장된 데이터들을 가지고 있다가, 배치 프로세스(스케쥴링)등을 통해 DB에 한번에 데이터 저장
  - 캐시 서버가 쓰기 작업을 DB로 비동기적 처리
- **장점**
  - 매우 빠른 쓰기 성능: 애플리케이션은 DB를 거치치 않으므로 빠른 응답 가능
  - DB 부하 감소: 주기적인 배치로 일괄 쓰기가 작동되므로 부하를 최소화 할 수 있음
  - 빠른 데이터 읽기: 최신 데이터가 항상 캐시에 존재
- **단점**
  - 데이터 유실 가능성: 캐시 서버 장애 시, DB에 반영되지 않은 데이터 손실 위험 존재
  - 데이터 일관성 문제: 캐시 서버와 DB가 비동기적으로 동기화되므로, DB 저장 전 데이터가 최신 데이터인지 확인할 수 없음

<br/>

<img src="/docs/img/cache/WriteThrough.png" style="background: white" alt="Look Aside Cache Strategy" width="670">

- **Write Through 전략 특징**
  - 애플리케이션이 캐시에 데이터를 저장
  - 캐시 서버가 동기적으로 DB에도 데이터를 저장
  - 데이터 일관성이 매우 중요할 때 적용
- **장점**
  - 데이터 일관성 유지:
  - 빠른 데이터 읽기: 최신 데이터가 항상 캐시에 존재
  - 데이터 유실 위험 없음: 데이터가 DB에 즉시 저장되므로 상대적으로 안전
- **단점**
  - 쓰기 성능 저하: 캐시와 DB에 동시에 데이터를 저장하므로 쓰기 속도가 저하될 수 있음
  - DB 부하 증가: 쓰기 요청 시 마다 DB는 요청을 수행하기 때문에 다수의 트랜잭션 발생으로 인한 DB 부하가 증가할 수 있음

<br/>

<img src="/docs/img/cache/WriteAround.png" style="background: white" alt="Look Aside Cache Strategy" width="670">

- **Write Around 전략 특징**
  - 애플리케이션이 항상 DB에 직접 데이터를 저장
  - 쓰기시 캐시에 데이터를 저장하지 않음
  - 쓰기 부하가 높은 시스템에서 효과적이지만, 읽기 성능이 중요한 시스템에서는 비효율적
- 장점
  - 캐시 부하 감소: 모든 데이터를 캐시에 저장하지 않기 때문에, 캐시 서버의 메모리 사용이 최적화
  - 자주 사용되지 않는 데이터에 효과적: 읽히지 않을 가능성이 높은 데이터는 캐시에 적재할 필요가 없으므로 불필요한 캐시 메모리 낭비 방지
- 단점
  - Cache Miss 증가: 별도의 캐시,DB 간의 동기화가 없으면 Cache Miss 발생이 증가
  - 읽기 성능 저하 가능성: 자주 조회되는 데이터의 경우 캐시에서 바로 가져올 수 없을 가능성 존재

### 3. 주의할 점

- **Cache Stampede**
  - Cache Stampede란, 캐시가 무효화(삭제)될 때 동시에 많은 요청이 캐시에 접근하여, 모든 요청이 동시에 DB를 조회하는 현상
  - DB의 부하가 급증하고, 성능 저하(트래픽 폭주)가 발생할 수 있음
  - 예를들어, 증권사 애플리케이션에서 장이 열리는 시간에 한꺼번에 요청이 들어와서 동일한 TTL 만료로 인해 다시 데이터를 조회하는 경우 모든 요청은 Cache를 뚫고 DB로 조회가 몰릴 것 이다.
- 해결방안
  - Mutex Lock
    - 캐시가 만료된 경우 DB를 동시에 조회하는 것을 방지하기 위해, 하나의 요청만 DB 조회를 수행하도록 설정(분산락)
    - 하나의 요청만 DB를 조회하여, DB 부하를 크게 줄일 수 있음
    - DB를 조회하는 데이터를 대기하는 시간 발생
  - Early Revalidation
    - 캐시 만료 전 백그라운드에서 미리 데이터를 갱신(배치)
    - 캐시가 만료되더라도 기존 데이터를 유지하면서 새로운 데이터를 미리 로드 시킴
    - 불필요한 데이터 갱신 가능성 존재
    - 변경되지 않은 데이터도 계속 갱신될 수 있음
  - Random TTL
    - 캐시 데이터별로 랜덤하게 TTL을 설정하여, 동시에 캐시 만료를 방지
    - TTL이 달라, 데이터 동기화가 어려울 수 있음
  - TTL Reset
    - 캐시 데이터가 조회될 때마다 TTL을 리셋시켜, 자주 조회되는 캐시 데이터의 경우, 캐시 만료를 방지
    - 핫 데이터(조회가 잦고 많은)는 항상 캐시 유지가능(Cache Miss 방지)
    - 오래된 데이터가 캐시에 남아 있을 수 있음
  - **추가로 고려해보면 좋을 해결 방안**
    - 멀티 Layer Caching
      - Local , Global 과 같이 레이어 별 캐싱 전략 적용
    - 캐시 서버 클러스터링 구축

---

## Redis

### Redis란?

### Redis의 자료구조


---

## Redis 활용해보기

---

## Redis를 이용한 콘서트 대기열 기능 개선

---